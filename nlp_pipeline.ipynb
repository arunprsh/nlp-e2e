{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and orchestrate NLP workflow using SageMaker Pipelines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterFloat, ParameterString\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from time import gmtime, strftime\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('__name__')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using SageMaker: 2.49.0\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Using SageMaker: {sagemaker.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = sagemaker.Session()\n",
    "bucket = session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "current_timestamp = strftime('%m-%d-%H-%M', gmtime())\n",
    "pipeline_name = f'nlp-pipeline-{current_timestamp}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bucket name = sagemaker-us-east-1-892313895307\n",
      "Role = arn:aws:iam::892313895307:role/service-role/AmazonSageMaker-ExecutionRole-20210714T091788\n",
      "Region = us-east-1\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Bucket name = {bucket}')\n",
    "logger.info(f'Role = {role}')\n",
    "logger.info(f'Region = {region}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define pipeline parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_instance_count = ParameterInteger(name='TrainingInstanceCount', default_value=1)\n",
    "training_instance_type = ParameterString(name='TrainingInstanceType', default_value='ml.p3.2xlarge')\n",
    "trained_model_s3_uri = ParameterString(name='TrainedModelS3Uri', default_value=f's3://{bucket}/pipeline/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters={'epochs': 1,\n",
    "                 'train_batch_size': 16,\n",
    "                 'model_name':'distilbert-base-uncased',\n",
    "                 'model_s3': trained_model_s3_uri.default_value,\n",
    "                 'output_dir':'/opt/ml/checkpoints'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator = HuggingFace(entry_point='train.py',\n",
    "                            source_dir='./src',\n",
    "                            instance_type=training_instance_type.default_value,\n",
    "                            instance_count=training_instance_count.default_value,\n",
    "                            role=role,\n",
    "                            transformers_version='4.6',\n",
    "                            tensorflow_version='2.4',\n",
    "                            py_version='py37',  \n",
    "                            disable_profiler=True,\n",
    "                            debugger_hook_config=False,\n",
    "                            #model_dir=trained_model_s3_uri.default_value,\n",
    "                            #output_dir=trained_model_s3_uri.default_value,\n",
    "                            #output_path=trained_model_s3_uri.default_value,\n",
    "                            checkpoint_s3_uri=trained_model_s3_uri.default_value,\n",
    "                            hyperparameters=hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingStep(name='train', step_type=<StepTypeEnum.TRAINING: 'Training'>, depends_on=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_step = TrainingStep(\n",
    "    name='train',\n",
    "    estimator=huggingface_estimator\n",
    ")\n",
    "\n",
    "training_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_path': 'Steps.train.ModelArtifacts.S3ModelArtifacts',\n",
       " '_shape_names': ['S3Uri'],\n",
       " '__str__': 'S3Uri'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_step.properties.ModelArtifacts.S3ModelArtifacts.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nendpoint_name = \"hf-clf-\" + strftime(\\'%d-%H-%M-%S\\', gmtime())\\ndeploy_model_script_uri = f\\'s3://{default_bucket}/{prefix}/code/deploy_model.py\\'\\n\\n\\ns3_client.upload_file(Filename=\\'./src/deploy_model.py\\', Bucket=default_bucket, Key=f\\'{prefix}/code/deploy_model.py\\')\\n\\ndeploy_model_processor = SKLearnProcessor(\\n    framework_version=\\'0.23-1\\',\\n    role=sagemaker_role,\\n    instance_type=\"ml.t3.medium\",\\n    instance_count=1,\\n    base_job_name=\\'deploy-model-processing-job\\',\\n    sagemaker_session=sagemaker_session)\\n\\ndeploy_step = ProcessingStep(\\n    name=\\'DeployModel\\', \\n    processor=deploy_model_processor,\\n    job_arguments=[\\n        \"--model-name\", endpoint_name, # just reusing endpoint name here \\n        \"--region\", region,\\n        \"--endpoint-instance-type\", deploy_model_instance_type,\\n        \"--model-s3-path\", model_s3_path, \\n        \"--endpoint-name\", endpoint_name],\\n    code=deploy_model_script_uri)\\n    '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "endpoint_name = \"hf-clf-\" + strftime('%d-%H-%M-%S', gmtime())\n",
    "deploy_model_script_uri = f's3://{default_bucket}/{prefix}/code/deploy_model.py'\n",
    "\n",
    "\n",
    "s3_client.upload_file(Filename='./src/deploy_model.py', Bucket=default_bucket, Key=f'{prefix}/code/deploy_model.py')\n",
    "\n",
    "deploy_model_processor = SKLearnProcessor(\n",
    "    framework_version='0.23-1',\n",
    "    role=sagemaker_role,\n",
    "    instance_type=\"ml.t3.medium\",\n",
    "    instance_count=1,\n",
    "    base_job_name='deploy-model-processing-job',\n",
    "    sagemaker_session=sagemaker_session)\n",
    "\n",
    "deploy_step = ProcessingStep(\n",
    "    name='DeployModel', \n",
    "    processor=deploy_model_processor,\n",
    "    job_arguments=[\n",
    "        \"--model-name\", endpoint_name, # just reusing endpoint name here \n",
    "        \"--region\", region,\n",
    "        \"--endpoint-instance-type\", deploy_model_instance_type,\n",
    "        \"--model-s3-path\", model_s3_path, \n",
    "        \"--endpoint-name\", endpoint_name],\n",
    "    code=deploy_model_script_uri)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    steps=[training_step],\n",
    "    sagemaker_session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'nlp-pipeline-07-18-16-54',\n",
       " 'parameters': [],\n",
       " 'pipeline_experiment_config': <sagemaker.workflow.pipeline_experiment_config.PipelineExperimentConfig at 0x7fd257d13710>,\n",
       " 'steps': [TrainingStep(name='train', step_type=<StepTypeEnum.TRAINING: 'Training'>, depends_on=None)],\n",
       " 'sagemaker_session': <sagemaker.session.Session at 0x7fd257cc7210>}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:892313895307:pipeline/nlp-pipeline-07-18-16-54',\n",
       " 'ResponseMetadata': {'RequestId': 'f63484d5-b7f5-4d02-9730-c7ce3da5faa5',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'f63484d5-b7f5-4d02-9730-c7ce3da5faa5',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '92',\n",
       "   'date': 'Sun, 18 Jul 2021 16:54:41 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = pipeline.create(role_arn=role)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:sagemaker:us-east-1:892313895307:pipeline/nlp-pipeline-07-18-16-54/execution/atehf72d087i'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CreatedBy': {'DomainId': 'd-dowart1jabkf',\n",
      "               'UserProfileArn': 'arn:aws:sagemaker:us-east-1:892313895307:user-profile/d-dowart1jabkf/ts-zd-e2e',\n",
      "               'UserProfileName': 'ts-zd-e2e'},\n",
      " 'CreationTime': datetime.datetime(2021, 7, 18, 16, 54, 42, 66000, tzinfo=tzlocal()),\n",
      " 'LastModifiedBy': {'DomainId': 'd-dowart1jabkf',\n",
      "                    'UserProfileArn': 'arn:aws:sagemaker:us-east-1:892313895307:user-profile/d-dowart1jabkf/ts-zd-e2e',\n",
      "                    'UserProfileName': 'ts-zd-e2e'},\n",
      " 'LastModifiedTime': datetime.datetime(2021, 7, 18, 16, 54, 42, 66000, tzinfo=tzlocal()),\n",
      " 'PipelineArn': 'arn:aws:sagemaker:us-east-1:892313895307:pipeline/nlp-pipeline-07-18-16-54',\n",
      " 'PipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:892313895307:pipeline/nlp-pipeline-07-18-16-54/execution/atehf72d087i',\n",
      " 'PipelineExecutionDisplayName': 'execution-1626627282196',\n",
      " 'PipelineExecutionStatus': 'Executing',\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '723',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Sun, 18 Jul 2021 16:54:42 GMT',\n",
      "                                      'x-amzn-requestid': 'e0193c5d-d9c3-406b-8eeb-25da6b911673'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': 'e0193c5d-d9c3-406b-8eeb-25da6b911673',\n",
      "                      'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "status = execution.describe()\n",
    "pprint(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
